# Sign Language Recognition (SLR) in deep learning. 
This is a comparative study using a custom CNN model with two other pre-trained architectures and fine tune them. 

The goal of this research is to successfully train different Convolutional Neural Network (CNN) models to identify sign language images, compare the performance of each model, and figure out the best model for image recognition and classification. The dataset contains 2515 images representing English alphabet letters and digits from 0-9 in American Sign Language. We use three different deep learning architectures to approach this computer vision problem. Specifically, we implement a custom CNN model and fine-tune two pre-trained models called InceptionV3 and ResNet50. These models were trained using TensorFlow and Keras. Each model consists of numerous convolutional and fully connected layers and is trained to classify images into one of 36 different classes. The models' architecture facilitates feature extraction and classification tasks, making it well-suited for image recognition problems. The performance of the custom CNN model, InceptionV3, and ResNet50 are 94.17%, 96.68%, and 98.67%. All three models generate extremely high accuracy which can contribute to helping researchers choose the best deep-learning method for Sign Language recognition and other image classification tasks. 

